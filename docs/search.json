[
  {
    "objectID": "posts/db-connections-command-line/index.html",
    "href": "posts/db-connections-command-line/index.html",
    "title": "Testing Database Connections from the Linux Command Line",
    "section": "",
    "text": "Posit Pro drivers allow you to easily connect your Workbench & Connect servers to external databases. The steps to install these drivers can be found here: https://docs.posit.co/pro-drivers/workbench-connect/\nYour best option is to isolate the product, and try to connect to your database natively from the command line. You can test connections by running isql, which is a command line tool for interactive SQL queries. To do so, you will need to create an odbc.ini file in the /etc directory.\nTo create a new DSN: 1. Edit the /etc/odbc.ini file. 2. Add a new entry for your desired database type by copying over the sample from /opt/rstudio-drivers/odbc.ini.sample. 3. Ensure that the Driver setting in the DSN refers to the corresponding driver name or path listed in /etc/odbcinst.ini. 4. Modify the entry with your desired connection parameters\nFor example, to add a SQL Server connection:"
  },
  {
    "objectID": "posts/db-connections-command-line/index.html#file-etcodbc.ini",
    "href": "posts/db-connections-command-line/index.html#file-etcodbc.ini",
    "title": "Testing Database Connections from the Linux Command Line",
    "section": "File: /etc/odbc.ini",
    "text": "File: /etc/odbc.ini\n[test]\nDriver = SQLServer\nServer = my.server.name\nDatabase = dbname\nPort = 1433\nTo test this connection, run the following command in the Linux terminal:\nisql -v test"
  },
  {
    "objectID": "posts/memory-load-balancing/index.html",
    "href": "posts/memory-load-balancing/index.html",
    "title": "Memory-Based Load Balancing on Posit Workbench",
    "section": "",
    "text": "The default load-balancing methods on Posit Workbench largely consider CPU utilization as the determinant for routing between nodes. There may be instances where administrators may wish to uses memory, as opposed to CPU-utilization, to route requests to nodes that are using less RAM. To enable this, set the configuration below in your /etc/rstudio/load-balancer configuration file:\n# /etc/rstudio/load-balancer\n[config] \nbalancer = custom \nFrom there, we will need to set the following directive in /etc/rstudio/rserver.conf:\n# /etc/rstudio/rserver.conf \nserver-health-check-enabled=1 \nFrom there, using your text editor of choice, edit the /usr/lib/rstudio-server/bin/rserver-balancer file with the below:\n#!/usr/bin/Rscript\n\nget_nodes &lt;- function(nodes = Sys.getenv(\"RSTUDIO_NODES\")) {\n  unlist(strsplit(nodes, \",\", fixed = TRUE))\n}\n\nget_health_check &lt;- function(node_address) {\n  con &lt;- url(sprintf(\"http://%s/health-check\", node_address))\n  on.exit(close(con))\n  readLines(con)\n}\n\nparse_health_check &lt;- function(health_check) {\n  fields &lt;- unlist(strsplit(health_check, \"\\n|,\"))\n\n  keys &lt;- sub(\n    \":\",\n    \"\",\n    regmatches(fields, regexpr(\"^[a-z\\\\-]+:\", fields))\n  )\n\n  values &lt;- sub(\n    \": \",\n    \"\",\n    regmatches(fields, regexpr(\":.+$\", fields))\n  )\n  data.frame(keys, values, stringsAsFactors = FALSE)\n}\n\nget_value &lt;- function(hc_table, hc_value) {\n  as.double(hc_table[hc_table[[\"keys\"]] == hc_value, \"values\"])\n}\n\nmain &lt;- function() {\n  nodes &lt;- get_nodes()\n  named_hc &lt;- setNames(lapply(nodes, get_health_check), nodes)\n  parsed_hc &lt;- lapply(named_hc, parse_health_check)\n  mem_percent &lt;- lapply(parsed_hc, get_value, \"memory-percent\")\n  least_mem &lt;- names(which.min(unlist(mem_percent)))\n\n  least_mem\n}\n\ncat(main())\nLastly, restart the Workbench & launcher services for this to take effect:\nsudo rstudio-server restart\nsudo rstudio-server restart"
  },
  {
    "objectID": "posts/ssl-workbench-launcher/index.html",
    "href": "posts/ssl-workbench-launcher/index.html",
    "title": "SSL with Posit Workbench + Launcher",
    "section": "",
    "text": "It’s possible to use an SSL certificate with the launcher in Posit Workbench. This may seem appealing, but what does this mean and how does it affect the interactions with Posit Workbench?"
  },
  {
    "objectID": "posts/ssl-workbench-launcher/index.html#can-i-use-the-same-ssl-for-my-posit-workbench-server-for-the-launcher",
    "href": "posts/ssl-workbench-launcher/index.html#can-i-use-the-same-ssl-for-my-posit-workbench-server-for-the-launcher",
    "title": "SSL with Posit Workbench + Launcher",
    "section": "Can I use the same SSL for my Posit Workbench server, for the launcher?",
    "text": "Can I use the same SSL for my Posit Workbench server, for the launcher?\nYes, however, it is strongly recommended & a best practice to ensure that the Launcher certificates are different from those used for Posit Server. The reason for this, is because typically, the Common Name(CN) for an SSL certificate will usually be specific to the name of the server that you’re using the certificate for (disregarding wildcard certificates and SAN certificates here). In most cases, Workbench will be available externally to the machine itself and can have an external-facing DNS name unique to your organization. For example, my-org.rsw-hostname.com. In this scenario, the server will likely be running on my-org.rsw-hostname.com, however, the launcher will be running on localhost. In this case, your server certificates CN will be my-org.rsw-hostname.com, and your Launcher certificates CN will be localhost.\nYou can use both the server and launcher on the same domain name so that they can share certificates, however, we wouldn’t recommend this as best practice.\n\nLauncher with SSL Explained\nConsider the following diagram:\n                 (a)           (b)\nBrowser (User) &lt;------&gt; RSP &lt;------&gt; Launcher\n                         ^\n                         | (c)\n                         v\n                     R Session                         \n\n(a) represents the communication between the Browser and Posit Server itself.\n(b) represents the communication between Posit Server and the Posit Job Launcher.\n(c) represents the communication between the RSession and the Posit Job Launcher. (Note: The Launcher starts the session in the backend, such as Slurm or Kubernetes, but does not communicate with the session directly).\n\nAll three lines of communication are over HTTP/S. The R Session communicates with the R session (c) the same way that a browser communicates with Posit Server (a). The R Session discovers the address with which to communicate with the server via the launcher-sessions-callback-address​ setting, which is why the setting needs to be exactly the same as what you would enter into the browser.\nThe settings that pertain to the encryption of (a) and (c) are as follows, that is, enabling HTTPS for communication with Posit Server:\n/etc/rstudio/rserver.conf:\nssl-enabled=1\nssl-certificate=&lt;/path/to/server/cert.pem&gt; \nssl-certificate-key=&lt;/path/to/server/key.pem&gt;\nAdditionally, the following settings are relevant to the configuration of HTTPS for (a) and (c), but not strictly required for enabling it:\n/etc/rstudio/rserver.conf:\nwww-address=&lt;my-org.rsp-hostname.com&gt;\nwww-port=&lt;port#, default 443 if ssl-enabled=1&gt;\nlauncher-sessions-callback-address=&lt;https://my-org.rsp-hostname.com[:port#]&gt;\nIn addition to the requirement that certificates defined in rserver.conf​ are added to the trusted certificate store of the host, they must have been generated with the correct Common Name​ (or CN​) matching the hostname of Workbench (most likely the same value as the www-address​), and the files must have restrictive permissions (root:root 400​). Additionally, the CA root must be trusted by any machines within your network that will access Workbench. For example, a user’s machines as well as Slurm compute nodes that will run R sessions.\nThe settings that pertain to the encryption of (b) are as follows (i.e. to enable HTTPS for communication between Posit Server and the Launcher):\n/etc/rstudio/rserver.conf:\nlauncher-use-ssl=1\nlauncher-address=&lt;launcher hostname or IP&gt;\nlauncher-port=&lt;port#&gt;\n\n/etc/rstudio/launcher.conf:\nenable-ssl=[0|1]\ncertificate-file=&lt;/path/to/launcher/cert.pem&gt;\ncertificate-key-file=&lt;/path/to/launcher/key.pem&gt;\naddress=&lt;launcher hostname or IP&gt;\nport=&lt;port#&gt;\nNote that the values of launcher-use-ssl​, launcher-address​, and launcher-port​ in rserver.conf​ should match the values of enable-ssl​, address​, and port​ in launcher.conf​ respectively. Also, note the lack of http://​ or https://​ in front of the launcher-address​ value. The protocol for communication is determined by the value of launcher-use-ssl​.\nThe Launcher certificates must be different certificates from those used for Posit Workbench. The correct CN ​for the Launcher’s certificates is the value of address​ in launcher.conf​. If Posit Workbench and the Launcher will be running on the same machine, localhost​ may be used. Another difference from the Posit Workbench certificates is that the Launcher certificates should be owned by the server-user​ and admin-group ​and defined in launcher.conf​. For example, if those values were left as they are on installation (both rstudio-server​) then the certificate files for the Launcher should have the permissions rstudio-server:rstudio-server 400​."
  },
  {
    "objectID": "posts/logrotate-posit-team/index.html",
    "href": "posts/logrotate-posit-team/index.html",
    "title": "Logrotate with Posit Teams",
    "section": "",
    "text": "You may wish to rotate the logs on your Posit Workbench, Package Manager, or Connect server. Whether to keep log files small, or to pass these files into third party solutions, it helps to know how this can be achieved.\nLargely, this involves creating new entries in your /etc/logrotate.conf file for the log file that you wish to rotate. Then, you can use the create function which follows the following syntax:\ncreate [mode] [user] [group]\nFor example, if you wanted to set 644 permissions on rstudio-connect.log , for both the rstudio-connect user & group, then you would set the following in your /etc/logrotate.conf:\n/var/log/rstudio/rstudio-connect/rstudio-connect.log { \nrotate 30 \ndaily \ncopytruncate \ncompress \ndelaycompress \nnotifempty \nmissingok \nsu root root \ncreate 644 rstudio-connect rstudio-connect\n}\nMore information on this can be found here: https://linux.die.net/man/8/logrotate"
  },
  {
    "objectID": "posts/vscode-session-timeouts/index.html",
    "href": "posts/vscode-session-timeouts/index.html",
    "title": "VScode Session Timeouts",
    "section": "",
    "text": "Currently, there is not a mechanism to timeout VS code sessions natively with directives in Posit configuration files.\nThat said, in the interim, you can set a timeout on the heartbeat file to automatically close sessions after some inactivity. The following GitHub issue contains more information: https://github.com/coder/code-server/issues/1636\nMore information on the heartbeat file itself can be found here: https://coder.com/docs/code-server/latest/FAQ#what-is-the-heartbeat-file\nIn addition, the following GitHub issues track session timeouts within code-server. It’s worth noting that these issues are not monitored or tracked by Posit, however, they provide potental alternatives for setting VS Code session timeouts:\nhttps://github.com/coder/code-server/issues/1274 https://github.com/coder/code-server/issues/5008"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cecil’s Data Science Blog",
    "section": "",
    "text": "SQLite Backup & Restore Scripts\n\n\n\n\n\n\nscript\n\n\ndatabase\n\n\n\n\n\n\n\n\n\nSep 30, 2024\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nRun Shiny Applications natively via the Linux command line\n\n\n\n\n\n\nLinux\n\n\nShiny\n\n\nR\n\n\n\n\n\n\n\n\n\nFeb 20, 2024\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nMemory-Based Load Balancing on Posit Workbench\n\n\n\n\n\n\nload balancing\n\n\nmemory\n\n\nlinux\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Database Connections from the Linux Command Line\n\n\n\n\n\n\ndatabase\n\n\nlinux\n\n\n\n\n\n\n\n\n\nMay 3, 2023\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nVScode Session Timeouts\n\n\n\n\n\n\nvscode\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting Workbench & Connect to AWS S3\n\n\n\n\n\n\nAWS\n\n\nS3\n\n\nR\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nLogrotate with Posit Teams\n\n\n\n\n\n\nlinux\n\n\nlogging\n\n\n\n\n\n\n\n\n\nJan 25, 2023\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting your Linux host to AWS EFS\n\n\n\n\n\n\nAWS\n\n\nEFS\n\n\nStorage\n\n\n\n\n\n\n\n\n\nDec 21, 2021\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nTroubleshooting Kubernetes Pods on AWS\n\n\n\n\n\n\nAWS\n\n\nKubernetes\n\n\nLinux\n\n\n\n\n\n\n\n\n\nDec 21, 2021\n\n\nCecil Singh\n\n\n\n\n\n\n\n\n\n\n\n\nSSL with Posit Workbench + Launcher\n\n\n\n\n\n\nSSL\n\n\nWorkbench\n\n\nLauncher\n\n\n\n\n\n\n\n\n\nNov 26, 2021\n\n\nCecil Singh\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Connecting-Workbench-Connect-to-AWS-S3/index.html",
    "href": "posts/Connecting-Workbench-Connect-to-AWS-S3/index.html",
    "title": "Connecting Workbench & Connect to AWS S3",
    "section": "",
    "text": "You may want to connect your Posit Workbench session to an S3 bucket to pull data from Amazon Web Services (AWS)."
  },
  {
    "objectID": "posts/Connecting-Workbench-Connect-to-AWS-S3/index.html#access-keys",
    "href": "posts/Connecting-Workbench-Connect-to-AWS-S3/index.html#access-keys",
    "title": "Connecting Workbench & Connect to AWS S3",
    "section": "Access Keys",
    "text": "Access Keys\nThere is an open-source package that allows you to connect your R session to the S3 API. It is useful when connecting your R session to AWS S3.\nTo install the package, you can run the following command in the R terminal:\ninstall.packages(\"aws.s3\")\nFrom there, we can use this library within our session:\nlibrary(aws.s3)\nOnce complete, we need to ensure that we have associated our appropriate RBAC (role-based access control) account to our R session. To do so, you can set the following variables within your environment using the R terminal:\nSys.setenv(\n\"AWS_ACCESS_KEY_ID\" = \"0000000\",\n\"AWS_SECRET_ACCESS_KEY\"= \"000000\",\n\"AWS_DEFAULT_REGION\" = \"us-west-2\",\n\"AWS_SESSION_TOKEN\" = \"0000000\")\nNote that the zeros used in the above are simply placeholders. You will need to replace the values within the quotation marks with the values that correspond to your AWS account. The region used is also a placeholder, you will need to change this if it is different to Oregon (us-west-2)."
  },
  {
    "objectID": "posts/Linux-EFS/index.html",
    "href": "posts/Linux-EFS/index.html",
    "title": "Connecting your Linux host to AWS EFS",
    "section": "",
    "text": "This guide assumes that you are familiar with the AWS console, and that you have configured an EFS file system as per the guide below:\nhttps://docs.aws.amazon.com/efs/latest/ug/gs-step-two-create-efs-resources.html"
  },
  {
    "objectID": "posts/Linux-EFS/index.html#assumptions",
    "href": "posts/Linux-EFS/index.html#assumptions",
    "title": "Connecting your Linux host to AWS EFS",
    "section": "",
    "text": "This guide assumes that you are familiar with the AWS console, and that you have configured an EFS file system as per the guide below:\nhttps://docs.aws.amazon.com/efs/latest/ug/gs-step-two-create-efs-resources.html"
  },
  {
    "objectID": "posts/Linux-EFS/index.html#mounting-your-efs-share",
    "href": "posts/Linux-EFS/index.html#mounting-your-efs-share",
    "title": "Connecting your Linux host to AWS EFS",
    "section": "Mounting your EFS Share",
    "text": "Mounting your EFS Share\nFirst, we need to make an EFS folder in the root directory:\ncd /\nsudo mkdir efs\nFrom here, we need to install the NFS client to connect the current server to the EFS share. The command used will defer depending on Linux distribution:\n\nUbuntu/Debian\nsudo apt-get -y install nfs-common\n\n\nRedhat/CentOS\nyum install nfs-utils\nFrom here, you can mount your EFS share to your server. You can select the “attach” button on the top-right hand corner of the file-systems page which will give you a link to connect. Alternatively, you can use something like this:\nsudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport &lt;hostname or IP Address here&gt;:/ efs\n\n\n\n\n\n\n\nOption\nResult\n\n\n\n\nnfsvers\nSpecifies which version of the NFS protocol to use.\n\n\nrsize\nThe maximum number of bytes in each network READ request that the NFS client can receive when reading data from a file on an NFS server. This is set to the maximum allowed value in the example above.\n\n\nwsize\nThe maximum number of bytes per network WRITE request that the NFS client can send when writing data to a file on an NFS server. This is set to the maximum allowed value in the example above.\n\n\nhard\nSpecifies whether the program using a file via an NFS connection should stop and wait (hard) for the server to come back online, if the host serving the exported file system is unavailable, or if it should report an error (soft).\n\n\ntimeo\nThe time in deciseconds (tenths of a second) the NFS client waits for a response before it retries an NFS request.\n\n\nretrans\nThe number of times the NFS client retries a request before it attempts further recovery action. If the retrans option is not specified, the NFS client tries each request three times.\n\n\nnorevsport\nSpecifies whether the NFS client should use a privileged source port when communicating with an NFS server for this mount point. If this option is not specified, or the resvport option is specified, the NFS client uses a privileged source port. If the noresvport option is specified, the NFS client uses a non-privileged source port.\n\n\n\nNOTE: You will need to replace  with your EFS servers IP address or hostname. It is important to allow your EFS client server IP address as an inbound firewall rule on your EFS cluster. It is also crucial to ensure that you have your EFS instance as an inbound firewall rule on your EFS client server.\nYou can check your mount points by running the command below:\ndf -h\nYou can test connectivity to your EFS share by going into your EFS directory and creating a test file. The example below creates a 30mb text file that you can use to verify data transfer to your shared directory:\ncd /\nsudo dd if=/dev/zero of=file.out bs=1MB count=30\nIf you can create that file, then you have the permissions to write to your EFS share."
  },
  {
    "objectID": "posts/run-shiny-apps-command-line/index.html",
    "href": "posts/run-shiny-apps-command-line/index.html",
    "title": "Run Shiny Applications natively via the Linux command line",
    "section": "",
    "text": "You may wish to run Shiny apps natively via the command line to help isolate code-related issues when when working with Posit Workbench or Posit Connect. Running code natively via the command line can help identify if issues are within code or within the product. Rscript allows you to test shiny applications and run them via the R command line. The following documentation contains more information on this:\nhttps://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/Rscript https://support.posit.co/hc/en-us/articles/218012917"
  },
  {
    "objectID": "posts/run-shiny-apps-command-line/index.html#example-usage",
    "href": "posts/run-shiny-apps-command-line/index.html#example-usage",
    "title": "Run Shiny Applications natively via the Linux command line",
    "section": "Example Usage",
    "text": "Example Usage\nFirst, let’s create our Shiny Web Application. For this example, we will be using a single file application (app.R), however, multiple file web applications can be used (ui.R, and server.R). The file is located in /home/posit/testapp/app.R. The content of this application can be seen below:\nlibrary(shiny)\n# Global variables can go here\nn &lt;- 200\n\n\n# Define the UI\nui &lt;- bootstrapPage(\n  numericInput('n', 'Number of Jobs', n),\n  plotOutput('plot')\n)\n\n\n# Define the server code\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    hist(runif(input$n))\n  })\n}\n\n# Return a Shiny app object\nshinyApp(ui = ui, server = server)\nOnce we have our application built, we can run this from the Linux command line using Rscript:\nCecil@RStudio:~# R -e \"shiny::runApp('/home/posit/testapp')\"\nThis will run your code natively via the R command line:\nCecil@PositWorkbench:~# R -e \"shiny::runApp('/home/posit/testapp')\"\n\nR version 4.1.2 (2021-11-01) -- \"Bird Hippie\"\nCopyright (C) 2021 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n&gt; shiny::runApp('/home/posit/testapp')\nLoading required package: shiny\n\nListening on http://127.0.0.1:5772\nIn this instance, 5772 is the port provided, however, this will be different for your specific application. Paste the URL into your web browser and you will be able to see your application presented."
  },
  {
    "objectID": "posts/sqlite-script/index.html",
    "href": "posts/sqlite-script/index.html",
    "title": "SQLite Backup & Restore Scripts",
    "section": "",
    "text": "Backup and Restore scripts for SQLite databases\n\nPython\n#Import the SQLite3 package for SQLite3 manipulation.\nimport sqlite3\n#Import shutil package for file operations.\nimport shutil\n\n#Specify database file paths.\n#This is hard-coded. In this instance, the SQLite directory will need to be adjusted. The backup directory is in the same path, however, appended with .bak.\nsource_db_filename = '/path/to/file.sqlite'\nbackup_db_filename = '/path/to/file.sqlite.bk'\n\n#Create a function that backs up the SQLite databases as specifed above.\ndef backup_database():\n    #Try-catch exception.\n    try:\n        #copy2 allows us to preserve all file metadata. copy() would copy the file data and permissions.\n        shutil.copy2(source_db_filename, backup_db_filename)\n        #Print success if backup is successful.\n        print(\"Backup successful.\")\n    #If the backup fails, let the user know.\n    except Exception as e:\n        print(f\"Backup failed: {str(e)}\")\n\n#Function to restore the database above from a backup\ndef restore_database():\n    #Try-catch exception\n    try:\n        #copy2 allows us to preserve all file metadata. copy() would copy the file data and permissions.\n        shutil.copy2(backup_db_filename, source_db_filename)\n        #Print success if restoration is successful.\n        print(\"Restore successful.\")\n    #If the backup fails, let the user know.\n    except Exception as e:\n        print(f\"Restore failed: {str(e)}\")\n\n#Allows the script to NOT be hard-coded. The user can select which options they would like.\n#Display user options.\nwhile True:\n    print(\"Options:\")\n    print(\"1. Backup Database\")\n    print(\"2. Restore Database\")\n    print(\"3. Quit\")\n    userSelection = input(\"Enter your userSelection. Specify 1, 2 or 3: \")\n\n    #Conditionals\n    if userSelection == '1':\n        backup_database()\n    elif userSelection == '2':\n        restore_database()\n    elif userSelection == '3':\n        break\n    else:\n        print(\"Invalid userSelection. Please enter 1, 2, or 3.\")\n\n\nBash\n#!/bin/bash\n\n#Define database file paths\nsource_db_filename=\"/path/to/file.sqlite\"\nbackup_db_filename=\"/path/to/file.sqlite.bk\"\n\n#Function to backup the database\nbackup_database() {\n    if cp -p \"$source_db_filename\" \"$backup_db_filename\"; then\n        echo \"Backup successful.\"\n    else\n        echo \"Backup failed.\"\n    fi\n}\n\n#Function to restore the database\nrestore_database() {\n    if cp -p \"$backup_db_filename\" \"$source_db_filename\"; then\n        echo \"Restore successful.\"\n    else\n        echo \"Restore failed.\"\n    fi\n}\n\n#Loop through the main menu\nwhile true; do\n    echo \"Options:\"\n    echo \"1. Backup Database\"\n    echo \"2. Restore Database\"\n    echo \"3. Quit\"\n    read -p \"Enter your selection (1, 2, or 3): \" userSelection\n\n    case $userSelection in\n        1)\n            backup_database\n            ;;\n        2)\n            restore_database\n            ;;\n        3)\n            break\n            ;;\n        *)\n            echo \"Invalid selection. Please enter 1, 2, or 3.\"\n            ;;\n    esac\ndone"
  },
  {
    "objectID": "posts/Kubernetes-AWS-Troubleshoot/index.html",
    "href": "posts/Kubernetes-AWS-Troubleshoot/index.html",
    "title": "Troubleshooting Kubernetes Pods on AWS",
    "section": "",
    "text": "Ensure that you have command-line access to the AWS console to access your AWS resources. You can use the AWS CLI tool through your terminal to verify this. You can run the command below to confirm if you are correctly connected to your AWS account:\naws sts get-caller-identity\nYou must also specify the name & region of your EKS cluster:\naws eks --region xx-xxxx-x update-kubeconfig --name xxxxxxxx\nFor example:\naws eks --region us-east-1 update-kubeconfig --name Rstudio-EKS\nIt also helps to set your namespace to the default namespace that you will be using:\nkubectl config set-context --current --namespace=NAMESPACE\nFor example:\nkubectl config set-context --current --namespace=rstudio"
  },
  {
    "objectID": "posts/Kubernetes-AWS-Troubleshoot/index.html#aws-access",
    "href": "posts/Kubernetes-AWS-Troubleshoot/index.html#aws-access",
    "title": "Troubleshooting Kubernetes Pods on AWS",
    "section": "",
    "text": "Ensure that you have command-line access to the AWS console to access your AWS resources. You can use the AWS CLI tool through your terminal to verify this. You can run the command below to confirm if you are correctly connected to your AWS account:\naws sts get-caller-identity\nYou must also specify the name & region of your EKS cluster:\naws eks --region xx-xxxx-x update-kubeconfig --name xxxxxxxx\nFor example:\naws eks --region us-east-1 update-kubeconfig --name Rstudio-EKS\nIt also helps to set your namespace to the default namespace that you will be using:\nkubectl config set-context --current --namespace=NAMESPACE\nFor example:\nkubectl config set-context --current --namespace=rstudio"
  },
  {
    "objectID": "posts/Kubernetes-AWS-Troubleshoot/index.html#troubleshooting-launched-pods",
    "href": "posts/Kubernetes-AWS-Troubleshoot/index.html#troubleshooting-launched-pods",
    "title": "Troubleshooting Kubernetes Pods on AWS",
    "section": "Troubleshooting Launched Pods",
    "text": "Troubleshooting Launched Pods\nlet’s check to see if we can access the Kubernetes API by launching a Kubernetes pod from our local server to our Kubernetes cluster. You can run the command below to see previously launched pods:\nkubectl get pods\nIf you have launched pods that you are having issues connecting to, you can run the command below for a more detailed description of which stage the pod is in, as well as any errors that may be associated with its launch:\nkubectl describe pod &lt;podname&gt;\nWhere  is the name of your Kubernetes pods, obtained by running kubectl get pods. For example:\nkubectl describe pod testpod"
  },
  {
    "objectID": "posts/Kubernetes-AWS-Troubleshoot/index.html#launching-a-test-pod",
    "href": "posts/Kubernetes-AWS-Troubleshoot/index.html#launching-a-test-pod",
    "title": "Troubleshooting Kubernetes Pods on AWS",
    "section": "Launching a test pod",
    "text": "Launching a test pod\nYou can launch a test pod to help narrow down connection issues when a pod is created. This will confirm that our localhost can launch pods into our Kubernetes cluster. The easiest way to do so, is to use kubectl to create a pod. Let’s create one called nginx:\nkubectl run nginx --image=nginx\nAlternatively, you can create a file containing the yaml that you would like to create your pod with. You can create this file by running the below:\nsudo touch pod.yaml\nThe contents of this file will contain the yaml configuration that you will use to launch the test pod. I’ve attached a sample configuration here:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    app: testing\nspec:\n  containers:\n  - image: nginx:latest\n    command:\n      - \"sleep\"\n      - \"604800\"\n    imagePullPolicy: IfNotPresent\n    name: nginx\n  restartPolicy: Always\n\n\n\n\n\n\n\nSpecification\nDescriptor\n\n\n\n\napiVersion\nThe version of the Kubernetes API to use\n\n\nkind\nThe type of object you wish to create\n\n\nmetadata\nThe type of data that helps uniquely identify the object\n\n\nspec\nThe specification of how you want the pod configured\n\n\n\nSave the file, and then apply the default configuration to use the yaml file that you created:\nkubectl apply -f pod.yaml\nWhen running this command, you should see confirmation that the pod has been launched:\ncecil@localhost:~$ kubectl apply -f pod.yaml\npod/nginx created\nOnce the pod has been created, you can SSH into the running pod by using the command below:\nkubectl exec -it nginx -- /bin/bash"
  }
]